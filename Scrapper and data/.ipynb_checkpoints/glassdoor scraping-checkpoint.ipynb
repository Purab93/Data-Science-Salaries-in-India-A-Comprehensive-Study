{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links to the pages for scrapping :\n",
    "    \n",
    "    https://www.glassdoor.co.in/Job/bengaluru-data-scientist-jobs-SRCH_IL.0,9_IC2940587_KE10,24.htm\n",
    "    https://www.glassdoor.co.in/Job/kolkata-data-scientist-jobs-SRCH_IL.0,7_IC2901633_KE8,22.htm\n",
    "    https://www.glassdoor.co.in/Job/chennai-data-scientist-jobs-SRCH_IL.0,7_IC2833209_KE8,22.htm\n",
    "    https://www.glassdoor.co.in/Job/pune-data-scientist-jobs-SRCH_IL.0,4_IC2856202_KE5,19.htm\n",
    "    https://www.glassdoor.co.in/Job/mumbai-data-scientist-jobs-SRCH_IL.0,6_IC2851180_KE7,21.htm\n",
    "    https://www.glassdoor.co.in/Job/hyderabad-data-scientist-jobs-SRCH_IL.0,9_IC2865319_KE10,24.htm\n",
    "    https://www.glassdoor.co.in/Job/new-delhi-data-scientist-jobs-SRCH_IL.0,9_IC2891681_KE10,24.htm\n",
    "    \n",
    "    https://www.glassdoor.co.in/Job/india-data-scientist-jobs-SRCH_IL.0,5_IN115_KE6,20.htm\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code doesnt load several pages of the webbapplication, we need to modify this to do that so that we can scrape all the jobs in India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = []\n",
    "salary = {'Company Name':[],'Job Title':[],'Salary':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(keyword, verbose):\n",
    "    \n",
    "    '''Gathers jobs as a dataframe, scraped from Glassdoor'''\n",
    "    \n",
    "    #Initializing the webdriver\n",
    "    options = webdriver.ChromeOptions()    \n",
    "    \n",
    "    #Change the path to where chromedriver is in your home folder.\n",
    "    driver = webdriver.Chrome(executable_path=\"D:/2) Coding/Jupyter Notebook/DS_salary_proj/Scrapper and data/chromedriver\", options=options)\n",
    "    driver.set_window_size(1120, 1000)\n",
    "    \n",
    "    keyword = '+'.join(keyword.split())\n",
    "    url = 'https://www.glassdoor.co.in/Job/jobs.htm?sc.keyword='+ keyword      \n",
    "    driver.get(url)\n",
    "    time.sleep(5) #adding some time for the webpage to load\n",
    "        \n",
    "    #searching for the total number of jobs in the link\n",
    "    num_jobs = int(''.join(driver.find_element_by_class_name(\"jobsCount\").text.split()[0].split(','))) #modifiing to scrape all the jobs instead of a single job \n",
    "    print(num_jobs)\n",
    "    \n",
    "    #Going through each job in this page\n",
    "    while len(jobs) < num_jobs:  #If true, should be still looking for new jobs.\n",
    "    \n",
    "        #Going through each job in this page\n",
    "        job_buttons = driver.find_elements_by_class_name(\"jl\")  #jl for Job Listing. These are the buttons we're going to click.\n",
    "        for job_button in job_buttons:  \n",
    "            \n",
    "            print(\"Progress: {}\".format(\"\" + str(len(jobs)+1) + \"/\" + str(num_jobs)))\n",
    "            if len(jobs) >= num_jobs:\n",
    "                break\n",
    "                \n",
    "            #removing job alert option \n",
    "            try:\n",
    "                driver.find_element_by_xpath('.//span[@class=\"SVGInline modal_closeIcon\"]').click()\n",
    "                print(\"job alert found and removed\")\n",
    "            except:\n",
    "                pass\n",
    "                                                   \n",
    "            try:\n",
    "                job_button.click()  \n",
    "            except:\n",
    "                time.sleep(3)\n",
    "                job_button.click()\n",
    "                time.sleep(1)\n",
    "            collected_successfully = False\n",
    "            \n",
    "            while not collected_successfully:\n",
    "                try:\n",
    "                    company_name = driver.find_element_by_xpath('.//div[@class=\"employerName\"]').text\n",
    "                    location = driver.find_element_by_xpath('.//div[@class=\"location\"]').text\n",
    "                    job_title = driver.find_element_by_xpath('.//div[contains(@class, \"title\")]').text\n",
    "                    job_description = driver.find_element_by_xpath('.//div[@class=\"jobDescriptionContent desc\"]').text\n",
    "                    collected_successfully = True\n",
    "                except:\n",
    "                    time.sleep(3)\n",
    "            \n",
    "            time.sleep(.5)\n",
    "            try:\n",
    "                rating = driver.find_element_by_xpath('.//span[@class=\"rating\"]').text\n",
    "            except NoSuchElementException:\n",
    "                rating = -1 #You need to set a \"not found value. It's important.\"\n",
    "\n",
    "            #Printing for debugging\n",
    "            if verbose:\n",
    "                print(\"Job Title: {}\".format(job_title))\n",
    "                print(\"Job Description: {}\".format(job_description[:500]))\n",
    "                print(\"Rating: {}\".format(rating))\n",
    "                print(\"Company Name: {}\".format(company_name))\n",
    "                print(\"Location: {}\".format(location))\n",
    "\n",
    "            #Going to the Company tab...\n",
    "            #clicking on this:\n",
    "            #<div class=\"tab\" data-tab-type=\"overview\"><span>Company</span></div>\n",
    "            try:\n",
    "                driver.find_element_by_xpath('.//div[@class=\"tab\" and @data-tab-type=\"overview\"]').click()\n",
    "\n",
    "                try:\n",
    "                    #<div class=\"infoEntity\">\n",
    "                    #    <label>Headquarters</label>\n",
    "                    #    <span class=\"value\">San Francisco, CA</span>\n",
    "                    #</div> \n",
    "                    headquarters = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Headquarters\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    headquarters = -1\n",
    "\n",
    "                try:\n",
    "                    size = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Size\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    size = -1\n",
    "\n",
    "                try:\n",
    "                    founded = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Founded\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    founded = -1\n",
    "\n",
    "                try:\n",
    "                    type_of_ownership = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Type\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    type_of_ownership = -1\n",
    "\n",
    "                try:\n",
    "                    industry = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Industry\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    industry = -1\n",
    "\n",
    "                try:\n",
    "                    sector = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Sector\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    sector = -1\n",
    "\n",
    "                try:\n",
    "                    revenue = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Revenue\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    revenue = -1\n",
    "\n",
    "                try:\n",
    "                    competitors = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Competitors\"]//following-sibling::*').text\n",
    "                except NoSuchElementException:\n",
    "                    competitors = -1\n",
    "\n",
    "            except NoSuchElementException:  #Rarely, some job postings do not have the \"Company\" tab.\n",
    "                headquarters = -1\n",
    "                size = -1\n",
    "                founded = -1\n",
    "                type_of_ownership = -1\n",
    "                industry = -1\n",
    "                sector = -1\n",
    "                revenue = -1\n",
    "                competitors = -1\n",
    "                \n",
    "            #used for debugging\n",
    "            if verbose:\n",
    "                print(\"Headquarters: {}\".format(headquarters))\n",
    "                print(\"Size: {}\".format(size))\n",
    "                print(\"Founded: {}\".format(founded))\n",
    "                print(\"Type of Ownership: {}\".format(type_of_ownership))\n",
    "                print(\"Industry: {}\".format(industry))\n",
    "                print(\"Sector: {}\".format(sector))\n",
    "                print(\"Revenue: {}\".format(revenue))\n",
    "                print(\"Competitors: {}\".format(competitors))\n",
    "                \n",
    "            jobs.append({\"Job Title\" : job_title,\n",
    "            \"Job Description\" : job_description,\n",
    "            \"Rating\" : rating,\n",
    "            \"Company Name\" : company_name,\n",
    "            \"Location\" : location,\n",
    "            \"Headquarters\" : headquarters,\n",
    "            \"Size\" : size,\n",
    "            \"Founded\" : founded,\n",
    "            \"Type of ownership\" : type_of_ownership,\n",
    "            \"Industry\" : industry,\n",
    "            \"Sector\" : sector,\n",
    "            \"Revenue\" : revenue,\n",
    "            \"Competitors\" : competitors})\n",
    "            #add job to jobs\n",
    "            \n",
    "            #-----------------------Added to extract salary from Indian company--------------------------#\n",
    "            salary_company=[]\n",
    "            jobtitle_company=[]\n",
    "            try:\n",
    "                driver.find_element_by_xpath('.//div[@class=\"tab\" and @data-tab-type=\"salary\"]').click()\n",
    "                \n",
    "                try:\n",
    "                    salaries = driver.find_elements_by_xpath('.//div[@class=\"hideHH alignRt avgSalaryCol\"]//div[@class=\"strong\"]')\n",
    "                    salary_company = [a.text for a in salaries]  \n",
    "                    jobtitles = driver.find_elements_by_xpath('.//div[@class=\"noPad expandHH\"]//div[@class=\"jobTitle strong\"]')\n",
    "                    jobtitle_company = [a.text for a in jobtitles]\n",
    "                except NoSuchElementException:\n",
    "                    salary_company.append(-1)\n",
    "                    jobtitle_company.append(-1)\n",
    "                    \n",
    "            except NoSuchElementException:  #Rarely, some job postings do not have the \"salary\" tab.\n",
    "                salary_company.append(-1)\n",
    "                jobtitle_company.append(-1)\n",
    "            \n",
    "            for i in range(len(jobtitle_company)):\n",
    "                salary['Company Name'].append(company_name)\n",
    "                salary['Job Title'].append(jobtitle_company[i])\n",
    "                salary['Salary'].append(salary_company[i])\n",
    "            \n",
    "            \n",
    "            # for debugging\n",
    "            if verbose:\n",
    "                print('list of the job titles: ',jobtitle_company)\n",
    "                print('list of salaries: ',salary_company)\n",
    "                print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "        \n",
    "            #----------------------------------------------------------------------------------------------#                \n",
    "\n",
    "        #Clicking on the \"next page\" button\n",
    "        try:\n",
    "            driver.find_element_by_xpath('.//li[@class=\"next\"]//a').click()\n",
    "            #we need to wait for JS to load\n",
    "            time.sleep(2) \n",
    "        except NoSuchElementException:\n",
    "            if num_jobs==len(jobs):\n",
    "                print(\"Scraping over after reaching target number of jobs.\\nNeeded : {}\\ngot : {}.\".format(num_jobs, len(jobs)))\n",
    "            else:\n",
    "                print(\"Scraping terminated before reaching target number of jobs.\\nNeeded : {}\\ngot : {}.\".format(num_jobs, len(jobs)))\n",
    "            break\n",
    "\n",
    "#This line converts the dictionary object into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2510\n",
      "Progress: 1/2510\n",
      "Progress: 2/2510\n",
      "Progress: 3/2510\n",
      "Progress: 4/2510\n",
      "Progress: 5/2510\n",
      "Progress: 6/2510\n",
      "Progress: 7/2510\n",
      "Progress: 8/2510\n",
      "Progress: 9/2510\n",
      "Progress: 10/2510\n",
      "Progress: 11/2510\n",
      "Progress: 12/2510\n",
      "Progress: 13/2510\n",
      "Progress: 14/2510\n",
      "Progress: 15/2510\n",
      "Progress: 16/2510\n",
      "Progress: 17/2510\n",
      "Progress: 18/2510\n",
      "Progress: 19/2510\n",
      "Progress: 20/2510\n",
      "Progress: 21/2510\n",
      "Progress: 22/2510\n",
      "Progress: 23/2510\n",
      "Progress: 24/2510\n",
      "Progress: 25/2510\n",
      "Progress: 26/2510\n",
      "Progress: 27/2510\n",
      "Progress: 28/2510\n",
      "Progress: 29/2510\n",
      "Progress: 30/2510\n",
      "Progress: 31/2510\n",
      "job alert found and removed\n",
      "Progress: 32/2510\n",
      "Progress: 33/2510\n",
      "Progress: 34/2510\n",
      "Progress: 35/2510\n",
      "Progress: 36/2510\n",
      "Progress: 37/2510\n",
      "Progress: 38/2510\n",
      "Progress: 39/2510\n",
      "Progress: 40/2510\n",
      "Progress: 41/2510\n",
      "Progress: 42/2510\n",
      "Progress: 43/2510\n",
      "Progress: 44/2510\n",
      "Progress: 45/2510\n",
      "Progress: 46/2510\n",
      "Progress: 47/2510\n",
      "Progress: 48/2510\n",
      "Progress: 49/2510\n",
      "Progress: 50/2510\n",
      "Progress: 51/2510\n",
      "Progress: 52/2510\n",
      "Progress: 53/2510\n",
      "Progress: 54/2510\n",
      "Progress: 55/2510\n",
      "Progress: 56/2510\n",
      "Progress: 57/2510\n",
      "Progress: 58/2510\n",
      "Progress: 59/2510\n",
      "Progress: 60/2510\n",
      "Progress: 61/2510\n",
      "Progress: 62/2510\n",
      "Progress: 63/2510\n",
      "Progress: 64/2510\n",
      "Progress: 65/2510\n",
      "Progress: 66/2510\n",
      "Progress: 67/2510\n",
      "Progress: 68/2510\n",
      "Progress: 69/2510\n",
      "Progress: 70/2510\n",
      "Progress: 71/2510\n",
      "Progress: 72/2510\n",
      "Progress: 73/2510\n",
      "Progress: 74/2510\n",
      "Progress: 75/2510\n",
      "Progress: 76/2510\n",
      "Progress: 77/2510\n",
      "Progress: 78/2510\n",
      "Progress: 79/2510\n",
      "Progress: 80/2510\n",
      "Progress: 81/2510\n",
      "Progress: 82/2510\n",
      "Progress: 83/2510\n",
      "Progress: 84/2510\n",
      "Progress: 85/2510\n",
      "Progress: 86/2510\n",
      "Progress: 87/2510\n",
      "Progress: 88/2510\n",
      "Progress: 89/2510\n",
      "Progress: 90/2510\n",
      "Progress: 91/2510\n",
      "Progress: 92/2510\n",
      "Progress: 93/2510\n",
      "Progress: 94/2510\n",
      "Progress: 95/2510\n",
      "Progress: 96/2510\n",
      "Progress: 97/2510\n",
      "Progress: 98/2510\n",
      "Progress: 99/2510\n",
      "Progress: 100/2510\n",
      "Progress: 101/2510\n",
      "Progress: 102/2510\n",
      "Progress: 103/2510\n",
      "Progress: 104/2510\n",
      "Progress: 105/2510\n",
      "Progress: 106/2510\n",
      "Progress: 107/2510\n",
      "Progress: 108/2510\n",
      "Progress: 109/2510\n",
      "Progress: 110/2510\n",
      "Progress: 111/2510\n"
     ]
    },
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=83.0.4103.61)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-410a35d5fad0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#This line will open a new chrome window and start the scraping.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mget_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data Science\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-9385e6d788e1>\u001b[0m in \u001b[0;36mget_jobs\u001b[1;34m(keyword, verbose)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mrating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.//span[@class=\"rating\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mNoSuchElementException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[0mrating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;31m#You need to set a \"not found value. It's important.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mtext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;34m\"\"\"The text of the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_ELEMENT_TEXT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=83.0.4103.61)\n"
     ]
    }
   ],
   "source": [
    "#This line will open a new chrome window and start the scraping.\n",
    "get_jobs(\"Data Science\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.DataFrame(jobs) \n",
    "df_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary = pd.DataFrame(salary) \n",
    "df_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.to_csv(\"Jobs_386\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary.to_csv(\"salary_386\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
